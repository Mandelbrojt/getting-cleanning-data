---
title: "Getting and Cleaning Data"
author: "Luis Moreno"
date: "9/21/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Note: the `echo = FALSE` parameter is added to the code chunk to prevent printing of the R code.  

## Reading Excel files  
```{r, eval = FALSE}
fileURL <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
download.file(fileURL, destfile = "./data/cameras.xlsx", method = "curl")
dateDownloaded <- date()
```

### read.xlsx()  
This function allows the user to read data from an Excel worksheet. It provides the conveniency of read.table by borrowing from its signature.  

### Main arguments for read.xlsx function  
```{reading_xlsx, eval = FALSE}
library(xlsx)
str(read.xlsx)
```

**file**: the path to the file to read.  
**sheetIndex**: a number representing the sheet index in the workbook.  
**sheetName**: a character string with the sheet name.  
**rowIndex**: a numeric vector indicating the rows you want to extract.  
**colIndex**: a numeric vector indicating the cols you want to extract.  
**head**: a logical value indicating whether the first row corresponding to the first element of the *rowIndex* vector contains the names of the variables.  

```{r, eval = FALSE}
colIndex <- 2:3
rowIndex <- 1:4
cameraDataSubset <- read.xlsx("./data/cameras.xlsx", sheetIndex = 1,
                              colIndex = colIndex, rowIndex = rowIndex)
cameraDataSubset
```

### Further Notes  
**write.xlsx**: it will write out an Excel file with similar arguments.  
**read.xlsx2**: it is faster than read.xsls but for reading subsets of rows is more unstable.  
**XLConnect**: this package has more options for writing and manipulating Excel files.  
**XLConnect vignette**: is a good place to start for that package.  
**Advise**: it is better to store data into a database or in comma separated files (.csv) or tab separated files (.tab/.txt).  

## Reading XML files  
### XML  
XML is the abbreviation for "Extensible Markup Language". It is frequently used to store *structured data*, particularly in internet applications.  
Its components are:  
 - Markup: labels that give the text structure.  
 - Content: the actual text of the document.  
 
 [XML Tutorial](https://www.w3schools.com/xml/)   
 
 ### Tags, elements and attributes  
  - Start tags: <section>  
  - End tags: </section>  
  - Empty tags: <line-break>  
  - Attributes: <step number="3"> Connect A to B. </step>  

```{Reading XML, eval = FALSE}
library(XML)
fileURL <- "./data/yuri_piquet.xml"
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
```

Setting "useInternalNodes" to TRUE, allows us to obtain all internal nodes from the XML file.  

### Accessing parts of the XML document with square brackets
```{r, eval = FALSE}
### Accessing parts of the XML document with square brackets
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[1]][[1]][[1]]
```

### Programatically extract objects from an XML file
If your variable (in this example the "rootNode") contains the entire XML, then this function will go through every single tagged element in the entire document. Generally, it will return all the text inside the XML file.  

```{r, eval = FALSE}
## Extract all text from the XML file
xmlSApply(rootNode, xmlValue)
```

### XPath Language  
- /node: returns the top level node.  
- //node: returns a node at any level.    
- node[@attr-name]: returns a node with an attribute name.  
- node[@attr-name='bob']: returns a node with an attribute name 'bob'.  

```{r, eval = FALSE}
## Extract all values from an specific node
xpathSApply(rootNode, "//SaldoActual", xmlValue)
xpathSApply(doc, "//NombreOtorgante", xmlValue)
xpathSApply(doc, "//CreditoMaximo", xmlValue)
```

## Reading HTML source code  
```{r, eval = FALSE}
fileURL <- "https://www.espn.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileURL, useInternal = TRUE)
## Look for elements that are list items that have a particular class
scores <- xpathSApply(doc, "//li[@class='score']", xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']", xmlValue)
```

## Reading JSON  
JSON stands for "Javascript Object Notation", ant it is used for lightweight data storage. It is similar in structure to XML files but different syntax/format.  
Data on JSON can be stored as:  
- Numbers  
- Strings  
- Boolean  
- Array  
- Object  

[More on JSON](https://en.wikipedia.org/wiki/JSON)  

### Reading data with jsonlite package  
```{r, eval = FALSE}
library(jsonlite)
## Read a JSON file for APPLE stock candle quotes from Finnhub
jsonData <- fromJSON("https://finnhub.io/api/v1/stock/candle?symbol=AAPL&resolution=1&from=1572651390&to=1572910590&token=br08q97rh5r9j5ovs4fg")
## Obtain the names in the JSON file
names(jsonData)
## Obtain nested objects in JSON
names(jsonData$c)
```

### Writing data frames into JSON  
```{r, eval = FALSE}
## Convert a data frame in R into JSON format
myjson <- toJSON(iris, pretty = TRUE)
cat(myjson)
## Convert back to JSON
iris2 <- fromJSON(myjson)
head(iris2)
```

### Further resources  
[JSON Official Website](https://www.json.org/json-en.html)  
[JSON Tutorial](https://www.r-bloggers.com/2013/12/new-package-jsonlite-a-smarter-json-encoderdecoder/)  

## The data.table Package  
All functions that accept data.frame can be applied over data.table.  
This package is written in C, making it much faster for subsetting, grouping, updating, among other.  
```{r, eval = FALSE}
library(data.table)
## Create a data frame using data.frame method
DF = data.frame(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
head(DF, 3)

## Create a data table using data.table method
DF = data.table(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
head(DF, 3)

## See all the data tables in memory
tables()

## Subsetting rows
DT[2, ]
DT[DT$y='a', ]
DT[c(2,3)]
```

### Subsetting in data.table  
- Subsetting function is modified for data.table.  
- The argument after the comma is called an "expression".  
- In R, an expression is a collection of statements enclosed in curly brackets.  

### Calculating values for variables with expressions  
```{r, eval = FALSE}
## Subsetting columns
DT[, c(2,3)]

#Subset the data table applying functions
DT[, list(mean(x), sum(z))]
DT[, table(y)]

## Add new columns
DT[, w:=z^2]

## Multiple step operations are combine with an expression that starts and ends with curly brackets, each statement is followed by a semicolon.
DT[, m:= {tmp <- (x+z); log2(tmp+5)}]

## plyr like operations
# Take the mean of x + w and group it by variable "a"
DT[, b:= mean(x+w), by = a]

## Special variables
# .N is an integer of length 1 cointaining the number
set.seed(123);
DT <- data.table(x = sample(letters[1:3], 1E5, TRUE))
## Count the number of times a value of column x appears
DT[, .N, by = x]
```

### Keys  
```{r, eval = FALSE}
## Set the key of the table to the column x
DT <- data.table(x = rep(c("a", "b", "c"), each = 100), y = rnorm(300))
setkey(DT, x)
DT['a']

## Join two tables by setting the keys of both
DT1 <- data.table(x = c('a', 'a', 'b', 'dt1'), y = 1:4)
DT2 <- data.table(x = c('a', 'a', 'b', 'dt2'), z = 5:7)
setkey(DT1, x); setkey(DT2, x)
merge(DT1, DT2)

## Fast reading of table files
big_df <- data.frame(x = rnorm(1E6), y = rnorm(1E6))
file <- tempfile()
write.table(big_df, file = file, row.names = FALSE, col.names = TRUE, sep = "\t", quote = FALSE)
system.time(fread(file))

system.time(read.table(file, header = TRUE, sep = "\t"))
```

### Further Reading  
[Latest Developments on Data Tables](https://r-forge.r-project.org/scm/viewvc.php/pkg/NEWS?view=markup&root=datatable)   
[Differences Between data.table and data.frame](http://stackoverflow.com/questions/13618488/what-you-can-do-with-data-frame-that-you-cant-in-data-table)  
[Notes on data.tables](https://github.com/raphg/Biostat-578/blob/master/Advanced_data_manipulation.Rmd)  

## Week 1 Quiz  
### Question 1  

The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here:   https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv  
How many properties are worth $1,000,000 or more?  
```{r, eval = FALSE}
library(readr)
us_comminities <- "./data/us_communities.csv"
df <- data.frame(read_csv(us_comminities))
VAL <- df$VAL
VAL <- na.omit(df$VAL)length(mio_val)
mio_val <- subset(VAL, VAL == "24")
length(mio_val)
```

### Question 2  
Use the data you loaded from Question 1. Consider the variable FES in the code book. Which of the "tidy data" principles does this variable violate?   
**Answer**: Each variable in the tidy data set has been transformed to be interpretable.  

### Question 3  
Download the Excel spreadsheet on Natural Gas Aquisition   Program here: https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx  
Read rows 18-23 and columns 7-15 into R and assign the result to a variable called "dat".    
What is the value of: sum(dat$Zip*dat$Ext,na.rm=T)  
```{r, eval = FALSE}
library(readxl)
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileURL, destfile = "./data/nat_gas_adq.xlsx")
xlsx_file_path <- "./data/nat_gas_adq.xlsx"
dat <- read_excel(xlsx_file_path, range = "G18:O23")
sum(dat$Zip*dat$Ext, na.rm = TRUE)
```

### Question 4   
Read the XML data on Baltimore restaurants from here:   https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml  
How many restaurants have zipcode 21231?  
```{r, eval = FALSE}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileURL, destfile = "./data/baltimore_restaurants.xml")
library(XML)
file_path <- "./data/baltimore_restaurants.xml"
doc <- xmlTreeParse(file_path, useInternalNodes = TRUE)
rootNode <- xmlRoot(doc)
zip_codes <- xpathSApply(rootNode, "//zipcode", xmlValue)
length(subset(zip_codes, zip_codes == "21231"))
```

### Question 5  
The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here:  
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv  
using the fread() command load the data into an R object "DT" The following are ways to calculate the average value of the variable "pwgtp15" broken down by sex.  
Using the data.table package, which will deliver the fastest user time?    

```{r, eval = TRUE}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
library(readr)
library(data.table)
file_path <- "./data/american_comm_survey.csv"
DT = fread(file_path)
system.time(mean(DT$pwgtp15, by = DT$SEX))
system.time(tapply(DT$pwgtp15, DT$SEX, mean))
system.time(DT[, mean(pwgtp15), by = SEX])
system.time(sapply(split(DT$pwgtp15, DT$SEX), mean))
system.time(mean(DT[DT$SEX == 1, ]$pwgtp15)) + system.time(mean(DT[DT$SEX == 2, ]$pwgtp15))

system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15), mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
```
**ANSWER: DT[,mean(pwgtp15), by=SEX]**  

## Reading from MySQL  
Install RMySQL 
If using Mac: install.packages("RMySQL")  
If using Windows:  visit **http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL**, or  **http://www.ahschulz.de/2013/07/23/installing-rmysql-under-windows/**  
### UCSC Database  
Database Help Page: **http://genome.ucsc.edu/goldenPath/help/mysql.html**  
### Connecting and listing databases in R  
```{r, eval = FALSE}
library(RMySQL)
ucscDB <- dbConnect(MySQL(), user = "genome",
                    host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDB, "show databases;"); dbDisconnect(ucscDB);
head(result, 5)
```
### Connecting to hg19 and listing tables  
```{r, eval = FALSE}
hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19",
                  host = "genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
```

